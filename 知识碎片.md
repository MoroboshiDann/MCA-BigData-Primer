# NIO

## 同步阻塞I/O

每个新增的网络连接，都会创建一个新的线程来处理，每个线程负责自己的socket输入输出。
socket进行I/O操作需要执行read系统调用，然后系统会切换为内核态，准备数据，然后将数据传输给线程。
在socket的数据准备好之前，会轮询判断是否已经准备好，直到准备好了才会读取或写入数据。
这样做线程之间不会相互阻塞，因为每个线程都是独立负责自己的socket。

这样做存在的问题：
- 当前socket会被阻塞等待，而不能进行其他操作。
- 需要频繁创建和销毁线程，这样做的成本很高，都需要重量级的系统调用才能完成。
- 如果同时有大量的网络连接到达，就会同时创建大量的Java线程，但是线程本身占用内存很大，会消耗大量的系统空闲内存。
- 线程的切换成本很高，而每个线程都需要不停地上处理机，判断是否准备完毕，会发生大量的线程切换。

## 非阻塞I/O NIO

非阻塞IO中，进行IO操作不再直接执行read系统操作，而是执行select操作，让系统准备数据，等到系统准备好数据后，再调用read将数据读取。执行select后，线程可以继续执行其他任务，而不需要阻塞等待。

非阻塞IO通常包含三部分：
- Channel，通道，类似于数据流，用于传输数据。当有网络连接时，一个Channel就对应一个网络连接。
- Buffer，缓冲区，用于存放待用户线程读取或用户线程写入待系统读取的数据。
- Selector，选择器，用于监听和查询IO事件。

通常非阻塞IO采用的是IO多路复用模型，即一个Selector可以同时监视多个socket的文件描述符。Selector通过监视IO事件来判断数据是否就绪。

IO事件，表示通道某种IO操作已经就绪。如一个Channel建立完成，此时就会发生一个IO事件，表示一个新连接已经建立好，这个IO事件就是“接收就绪”；如果一个Channel有数据可读，就会发生IO事件，代表该数据连接已经准备好，该IO事件为“读就绪”。

Selector的工作就是查询注册到其上的所有通道的IO事件。

因此，使用NIO第一步为，为每一个网络连接创建一个Channel，并将Channel注册到Selector；第二步，通过Selector提供的select方法查询这些注册通道的IO事件。

优点：不需要为每一个网络连接创建一个线程，大大减少了系统开销。

### select，poll，epoll



# Netty

​	采用的是NIO的多路复用模式，每当有网络连接到达时，就会为其建立一个Channel对象，并注册到Selector上。

​	当Channel的IO事件到达时，就会调用ChannelHandler中对应的方法来处理通道中的数据。如Channel建立好之后，此时就会发生IO事件“接受就绪”，Netty服务器可以读取客户端通过Channel发送来的数据，就会调用`channelRead`方法。

​	



# Hystrix

​	提供服务降级、熔断、服务隔离功能的工具。

## 服务隔离

​	如果不进行隔离，网关上所有的请求在转发时，使用的是公共的线程池。如果一个服务的请求量突然变大，将线程池资源消耗殆尽，不仅会对当前服务造成影响，也会对其他服务的亲贵造成影响，因为没有可用线程了。

​	Hystrix中，提供了线程池隔离和信号量隔离。线程池隔离是指，可以给每个服务的请求划分Group，每个Group维护一个线程池，当前服务的请求只能使用当前Group的线程，这样就不会对其他服务造成影响。即，一个到达网关的请求都有一个线程，然后再去当前请求服务的线程池中获取线程，调用远程服务。

​	信号量隔离是指，当前的请求线程先去获取信号量，然后直接在当前线程上执行远程服务的调用，如果获取信号量失败就阻塞等待。

​	对比：

- 前者收到线程池中线程数量的限制。后者收到信号量大小的限制。
- 前者需要创建额外线程，并且需要维护线程池，开销较大。后者由于都是在一个线程上进行的，所以开销较小。

> 在网关项目中，路由过滤器中在调用远程服务时，使用的是AsyncHttpClient，即将发送HTTP请求的任务交给一个CompletableFuture来执行，该CF提供了一个回调，当任务执行完成或出现异常时，会在调用CF的线程中执行该回调方法。也就是说，CF会将执行其的线程阻塞，等待回调函数的执行。
>
> 使用了Hystrix后，将服务进行了隔离，就可以避免一个服务的请求过大，导致短时间内占用过多的线程资源。

## 降级与熔断

### 降级

​	Hystrix可以在不修改原代码的情况下，实现服务降级。只需要重写`getFallback()`方法，即可。

​	当请求失败或者超时时，我们可以返回一个托底数据，如返回一个设定好的响应数据，避免请求长时间占用服务器资源。

### 熔断

​	Hystrix的熔断器会根据错误率和超时率来判断是否打开熔断器，如果打开熔断器，在一段时间内就会拒绝请求，直接执行降级逻辑，减轻故障服务器的负载。



# ElasitcSearch

## 倒排索引

​	MySQL等采用的是正向索引，如果直接根据索引字段进行检索，就可以直接使用建立好的索引快速定位到相关记录。但是，如果是要进行模糊匹配，无论是否是根据索引字段检索，都只能遍历所有记录来判断查找。

​	倒排索引，包含文档和词条两个概念。文档就是被存储的数据，即记录；词条就是将文档按照一定算法进行分词，得到的词条。

​	对于ES中存储的文档，首先对每一条文档进行分词，然后可以得到当前文档中所有词条和该文档的对应关系，存储在一个Map中<term, 文档id>，所有文档都分词后，就可以得到每个词条都出现在哪些文档中。

​	需要检索时，只需要对检索条件进行分词，然后分别使用分得的词条查找其出现过的文档id，然后取交集，就能够定位到一个文档。

正向索引：

- 优点：
  - 可以给多个字段设置索引。
  - 根据索引字段搜索记录，速度非常快。
- 缺点：
  - 根据非索引字段，或索引字段中的部分词条进行检索时，只能扫描全表。

倒排索引：

- 优点：
  - 根据词条搜索、模糊搜索时，速度很快。
- 缺点：
  - 只能给词条创建索引，而不是字段。
  - 无法根据字段做排序。

## 存储结构

​	ES面向文档存储，一条文档对应的是一条记录。文档会被序列化为JSON格式来存储，每个字段对应的是JSON的一个属性。

​	ES中的索引index，对应的是MySQL中的表。一条索引中包含了多个文档。

## 对比MySQL

- MySQL擅长事务类型操作，可以确保数据的安全和一致性。
- ES擅长对海量数据做检索、分析和计算。



# MySQL

为什么MySQL单表记录数量不要超过2000w条

答：我自己做过对比，建立一张表，设置四五个字段。然后分别在100w、500w、1000w、2000w记录数量下执行count(1)和条件查询。其结果如下：

| 记录数量 | count(1) | 条件查询 |
| -------- | -------- | -------- |
| 100w     | 0.04     | 0.219    |
| 500w     | 0.234    | 1        |
| 1000w    | 0.46     | 2.1      |
| 2000w    | 18       | 5.57     |

可以看到当数据量到达2000w时，查询时间确实会激增。但是此时，并没有到达MySQL单表记录数量的上限，一般自增主键为int型，可以存储21亿条记录，如果是bigint就会更大。

原因：

- 数据量超过2000w，会导致b+树层级变高，需要的IO数量也增加。
- InnoDB会将表的索引加载进内存，但是数据量过大导致索引不能全部被加载，会产生额外的IO。



# Hippo4j

​	核心包括两部分：

- Hippo4j Config：这是一个配置中心，可以基于Nacos、Eureka等常见的配置中心来实现。用来管理线程池的参数。支持运行时监控和报警功能，不需要额外的中间件。
- Hippo4j Server：一个Web服务器，提供可视化的页面来管理线程池的创建、更改和查看。

## 动态线程池怎么体现的

​	动态线程池的动态怎么体现的：

- 参数动态调整：Hippo4j支持在运行时动态更改线程池的参数，例如核心线程数量、最大线程数、队列容量等。可以直接在配置中心来修改，当参数发生变化时，Hippo4j可以自动同步到线程池中，不需要重启服务。
- 动态监控与报警：系统会在检测到线程池的运行状态异常时(线程数、任务队列长度等)，发出警报。

## 为什么选取HIppo4j

​	首先，线程池的参数是比较难确定的，服务中对线程的需求可能会动态变化，所以需要能够动态管理线程池的能力。其次，Java虽然提供了ThreadPoolExecutor来实现线程池，可以修改其参数来实现线程池动态管理，但是要自己手动实现比较繁琐，经常需要重启服务才能比较方便地修改参数。

​	而Hippo4j使用起来比较方便，只需要将需要用到的线程池注入到Spring IoC容器中，就可以实现动态监管。





# RRateLimmiter

​	Redission包中，用于实现限流的工具。采用的是令牌桶的思想来实现分布式限流。其主要特点如下：

- 令牌按照指定速率生成。
- 令牌存放在桶中，如果桶存满了，多于生产的令牌就会直接丢弃。
- 请求到达时，先尝试从桶中获取令牌，获取成功才能够继续执行。
- 如果桶已经空了，尝试获取令牌的请求会被直接丢弃。



# RabbitMQ

## 1. RabbitMQ是什么

​	RabbitMQ是一种消息队列，实现了高级队列协议(AMQP)，是一种消息中间件。RabbitMQ的模型结构和AMQP的结构是一致的。

## 2. AMQP是什么

​	是一种高级队列协议，对消息队列的功能做出了一定约束。它主要包含三部分：交换器、队列、绑定。

- 交换器：用于将生产者的消息路由至指定队列的组件。
- 队列：用来存储消息的数据结构，位于硬盘或内存中。
- 绑定：一套规则，指定了交换器应该将消息路由至哪个队列中。

​	RabbitMQ中，一个Broker代表了一个RabbitMQ的服务器，一个Broker中包含多个交换器和队列。交换器需要与队列之间进行绑定，交换机需要根据`binding key`来绑定一个队列。生产者的消息发送给交换器，并需要和消息一同发送一个`routing key`。交换器根据`routing key`和`bingding key`进行模糊匹配，如果匹配成功，就将消息转发至对应的队列。

## 3. 为什么需要消息队列(优缺点)

​	有如下原因：

1. 异步处理：对于Web应用，客户请求中可能包含复杂耗时的操作，如果不进行异步处理，就会造成客户端长时间等待。而如果采用消息队列，服务端可以在将请求处理的消息发送至消息对立后就直接给客户端一个响应，减少了响应时间，提高用户体验。
2. 解耦：生产者只需要负责将消息发送至消息队列，消费者只需要监听队列，从中取出消息进行消费。二者之间不需要有任何耦合，提高了系统的扩展性。同时，如果生产者和消费者的速率不匹配，如果不使用消息队列，就会造成速率较快的一方等待另一方处理的情况。
3. 削峰/限流：可以将短时间内高并发产生的消息存储在消息队列中，然后再根据自己的能力再去慢慢消费，避免高并发的请求直接将服务端击垮。

​	缺点：

1. 系统的可用性肯能会降低：系统会引入更多的外部依赖，如果MQ节点挂掉了，整个系统也会崩溃。
2. 系统的复杂性提高：业务流程可能需要重新设计。
3. 需要保证消息消费的顺序性。
4. 可能会造成系统不一致性：假设A为生产者，BCD为消费者，A发送消息后返回成功，但是BCD中，BC处理成功，数据库更新成功，结果D处理失败，此时系统是不一致的。

## 4. 如何保证消息的可靠性

### 生产者到RabbitMQ

​	采用事务机制或Confirm机制，二者互斥。

#### 事务机制

​	事务机制是AMQP协议规定的。提供了三个方法：`txSelect()` `txCommit()`和`txRollback()`。`txSelect()`将channel设置为transaction模式，相当于开启事务，此时就可以开始向Broker发送消息了。发送完毕，调用`txCommit()`方法提交事务，如果提交成功，则消息一定到达了Broker，如果失败就要调用`txRollback()`方法来回滚事务。

#### Confirm机制

​	事务机制会降低RabbitMQ的吞吐量。Confim模式会更高效。

​	生产者将channel设置为Confirm模式后，所有在该channel上发布的消息都会被分配一个唯一的ID。一旦消息发送到Broker，就会返回一个确认给生产者，包含消息的ID。如果消息是可持久化的，会在消息写入磁盘后发出确认。

​	Confirm机制是异步的，生产者在等待确认时，还可以继续发出消息。

> ​	这个唯一ID还可以用于消费端消息去重，保证消息的唯一性。

### RabbitMQ自身

1. 持久化
2. 集群
4. 镜像模式

#### 持久化

​	RabbitMQ的持久化分为三种：

- 交换器的持久化：交换器在声明时如果不指定为durable，MQ重启后交换器的元数据会丢失，不能将消息发送到该交换器。
- 队列持久化：队列持久化只能保证MQ重启时队列的元数据不会丢失，不能保证消息不丢失。
- 消息持久化：通过消息的投递模式来实现，可以控制每一条消息是否持久化。消息持久化会将消息写入到磁盘中，会降低MQ的吞吐量，因此需要在可靠性和吞吐量之间权衡。

​	持久化的消息会在进入队列时就写入磁盘，内存中会保存部分副本来提高效率。而非持久化的消息只会保存在内存中。

#### 集群

​	RabbitMQ集群的结构如图所示：

![](rabbitmq-cluster%201.png)

​	集群中所有节点上的交换器Exchange是一致的，即交换器在每个节点上都有副本。而消息队列只会存在于创建时所在的节点上，其他节点上只知道该队列的元数据和指向该队列所在节点的指针。

​	RabbitMQ集群会始终同步四种数据：

1. 交换机元数据：交换器名称、类型和属性。
2. 队列元数据：队列名称和它的属性。
3. 绑定元数据：交换器名称、类型和属性。
4. vhost元数据：为vhost内的队列、交换器和绑定提供命名空间和安全属性。

​	因此，当用户访问集群中任意一个节点时，查询到的交换器、队列、vhost的信息都是相同的。

> 为什么只同步元数据：
>
> 1. 节省存储空间，如果将每个节点上队列中所有的消息都完全拷贝，那么每个节点占用的存储空间会非常大，集群的消息积压能力会降低，和单个节点没有区别。
> 2. 提高性能：如果拷贝消息，消息的发布者就会耗费大量时间来将消息复制到每个节点上，造成大量开销。

​	如果客户端连接的节点上，没有目标队列，此节点就起到了一个路由转发的作用，将消息发送至对应节点中的队列中或从中取出消息交给客户端。

#### 镜像队列

​	如果RabbitMQ只有一个节点，那么该节点失效时就会导致整个服务不可用。虽然RabbitMQ可以搭建集群，但是集群中每个节点上的队列是不同的，单个节点失效时，队列中的消息还是会丢失或暂时不可用。镜像队列是基于集群模式的，每个队列都有一个master和若干个slave。master负责读写，而slave只负责备份。每个队列的master都在自己指定的节点上，而不是所有的master都在一个节点上。

## 5. 交换器的四种模式

- fanout：将发送到该交换器上的消息，转发至其所有绑定的队列中。
- direct：将消息转发至`binding key`和`routing key`完全一致的队列中。
- topic：给队列绑定一个匹配模式，类似于正则表达式，交换器将根据模式匹配来路由消息。
- headers：不根据`routing key`来处理消息，而是在绑定交换器和队列时，指定一个键值对header。发送至交换机的消息也需要在headers中指定键值对。交换器根据键值对来匹配。

## 6. 消息生产者的使用过程

### 生产者

1. Producer连接至Broker，建立连接Connection，并开启通道Channel。
2. Producer声明一个交换器，并设置好相关属性。
3. Producer声明一个队列，并设置好相关属性。
4. Producer通过`binding key`将交换器和队列绑定起来。
5. Producer将消息通过channel发送至Broker。
6. 交换器根据`routing key`来匹配队列，如果匹配失败根据用户的配置来决定丢弃消息或退回。
7. 关闭channel。

### 消费者

1. Consumer先连接至Broker，建立Connection，并开启Channel。
2. 向Broker请求消费对应消息对立中的消息，设置回调函数。
3. 等待Broker回应并投递相应队列中的消息，接收消息。
4. Consumer消费消息，并返回ack。
5. Broker删除对应消息。
6. 关闭Channel。

## 6. 死信队列和死信交换器

​	当一个消息出现：超过存活时间、消息被拒、消息队列已满无法添加。就会变为死信消息。

​	死信消息会被发送至一个死信交换器中。绑定到死信交换器上的队列就是死信队列，死信交换器会将消息再转发至死信队列中。

## 7. 延迟队列和优先级队列

​	延迟队列，消息发送至队列后，不让生产者立即拿到消息，而是等待特定时间后，再让消费者进行消费。

​	优先级队列，优先级较高的消息会被先消费。但是，如果消费速率较高，且Broker没有消息积压的情况下，优先级没有意义。

## 8. 消费者获取消息的方式

### PUSH

​	通过`@EnableRabbit`和`@RabbitListener`两个注解来实现。这种模式下，消息队列会主动将消息推送至消费者。

### PULL

​	通过`AmqpTemplate`或`RabbitTemplate`提供的方法来主动从消息队列拉取消息。如果消息队列没有消息，就会拉取到null值。



# Redisson

## 1. 分布式锁如何实现

## 2. 加锁如何保证加锁过程原子性

​	Redission中没有通过SETNX来实现加锁，而是自己实现了一套逻辑。先获取锁对象，然后调用锁对象的`lock()`方法，执行加锁向redis服务器发送一段lua脚本。加锁过程最终是通过lua脚本来实现的，而Redis在执行lua脚本时可以保证是原子性的。因此，加锁过程就是依赖lua脚本的。

​	Redis执行lua脚本时，会将脚本作为一个整体执行，中间不会插入其他指令，因此可以保证原子性。

## 3. 如何自动延长锁的释放时间，以及过期自动释放锁

​	lua脚本在加锁时，会默认锁的TTL为30s，避免出现死锁的情况。但是，如果线程在30s内没执行完任务，锁就会被释放，就会造成线程安全问题，因此Redission引入了watchdog机制。如果客户端加锁成功之后，没有指定锁的过期时间，就会设置一个定时任务，每10s执行一次，将锁的释放时间再延长至30s。

​	如果在加锁时指定了释放时间，就不会开启watchdog机制，这样就不会自动续约，从而可以实现到期自动释放。

## 4. 如何实现可重入锁

​	可重入锁是指，同一个客户端的同一个线程，可以重复对一个锁对象加锁。 如果是非可重入锁，在持有锁的状态下，再次加锁就会出现死锁。

​	可重入锁是通过lua脚本来实现的，lua脚本会判断当前已经加锁的key，对应的加锁线程是否为同一个，如果是就将线程对应的枷锁次数+1。

## 5. 如何主动释放锁

​	如果加锁时没有指定释放时间，且不主动释放锁，就会导致watchdog不断地续约，从而引起死锁；而如果指定了释放时间，但是任务提前完成，不主动释放就会造成资源浪费。

​	Redission通过`unlock()`方法来释放锁，同样是让redis执行一段lua脚本。lua脚本首先判断来释放锁的线程和加锁的线程是否为同一个，如果不是直接返回，防止释放了其他线程的锁导致并发安全问题；然后，将加锁次数-1，并判断加锁次数，如果小于零证明没有重入锁，锁已经释放；如果大于零，证明当前锁为重入锁，并没有完全释放。

## 6. 如何实现线程互斥

​	首先，redis中lua脚本的加锁逻辑只有一个线程能执行，即lua脚本是原子性的。然后，一旦有线程加锁成功，另外再有线程来加锁时就会判断是否为上一个加锁线程，如果不是就直接返回而不会加锁，从而保证了线程互斥。

## 7. 加锁失败的处理

​	加锁失败后，会进入自旋加锁状态，不断地循环尝试加锁。但是，在循环中，会判断当前时间和比较时间，如果超出设定的时间就会放弃加锁，防止陷入死锁。(线程释放锁失败，而其他线程一直在循环尝试)

## 8. 如何实现公平锁

​	公平锁是指线程加锁成功的顺序和线程申请加锁的顺序是一致的。其优点是能够按序平均分配锁资源，但缺点是按需唤醒线程的开销较大，执行性能不高。非公平锁的执行性能较高。

​	Redisson中RedissionFairLock类就是公平锁的实现，其交给redis执行的lua脚本逻辑如下：如果线程加锁失败了，就将线程放入到一个set集合中，由于set是有序的，所以线程在set中的顺序就代表了加锁的顺序。当锁释放时，set头部的线程被取出进行加锁。这样就实现了加锁的顺序性。

## 9. 如何实现读写锁

​	现实的业务中，读多写少的场景会有很多，如果使用独占锁，就会大大降低并发性能。而读写锁的特点为：读操作不互斥，写操作之间和写操作与读操作之间互斥。就可以有较好的并发性能。

​	Redission中首先获得一个RReadWriteLock锁对象；需要加读锁时，通过其获得读锁对象，需要加写锁时，获取写锁对象。

​	Redis执行lua脚本加锁成功后，会维护一个Hash数据，保存当前线程加锁的次数。在读写锁这里，会额外添加一个mode字段，用来记录当前锁的类型，并根据类型来判断后续是否能加锁成功：

- 如果当前没有加锁，无论是什么类型的锁都可以加锁成功。
- 如果mode为读锁，加锁线程为读锁，加锁成功。
- 如果mode为读锁，加锁线程为写锁，加锁失败。
- 如果mode为写锁，无论加什么锁都会失败(除非加锁线程就是当前已经加的锁的线程，即重入)。

## 10. 如何实现RedLock

​	要设置一个Redis集群，当线程尝试加锁时，就要对每个节点进行尝试加锁，如果超过半数的节点都加锁成功，才能加锁成功，否则就是加锁失败。

​	如果加锁成功时，所有加锁操作的总和大于锁存活时间的一半，也要返回加锁失败，因为剩余时间用于释放锁，没有时间进行任务操作了。

## 11. RRateLimmiter

​	







